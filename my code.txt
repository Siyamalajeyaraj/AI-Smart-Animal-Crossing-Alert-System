import streamlit as st
import cv2
from ultralytics import YOLO
import pygame
import threading
import time
import tempfile

# Load YOLOv8 medium model for better accuracy
model = YOLO("yolov8m.pt")  # Change to yolov8l.pt if you want even higher accuracy

# Initialize pygame mixer for playing sound
pygame.mixer.init()

# Function to play alert sound without freezing Streamlit
def play_alert_sound():
    def _play():
        pygame.mixer.music.load("alert.mp3")  # Make sure alert.mp3 is in the same folder
        pygame.mixer.music.play()
    threading.Thread(target=_play).start()

# Detection log list
detection_log = []

# To avoid repeating alert sound for the same animal
last_alert = None

st.title("üêæ AI Smart Animal Crossing Alert System")
st.markdown("### Real-time Animal Detection to Prevent Road Accidents üöóüêÑ")

# Sidebar section for log
st.sidebar.header("üìã Detection Log")

# Upload a video or use webcam
option = st.radio("Choose Input Source:", ("Upload Video", "Use Webcam"))

if option == "Upload Video":
    video_file = st.file_uploader("Upload a road video file", type=["mp4", "avi", "mov"])
    if video_file:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_file.read())
        cap = cv2.VideoCapture(tfile.name)
elif option == "Use Webcam":
    cap = cv2.VideoCapture(0)

# Process video if available
if 'cap' in locals():
    stframe = st.empty()
    alert_placeholder = st.empty()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Run YOLO detection
        results = model(frame)
        detections = results[0].boxes.data

        # Check if any animals detected
        animal_detected = False
        detected_name = ""

        for box in detections:
            conf = float(box[4])
            if conf < 0.5:  # Ignore low-confidence predictions
                continue
            cls = int(box[5])
            label = model.names[cls]
            if label in ["dog", "cat", "cow", "elephant", "horse", "sheep", "bear", "zebra", "giraffe"]:
                animal_detected = True
                detected_name = label
                x1, y1, x2, y2 = map(int, box[:4])
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"{label} ({conf:.2f})", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # Display alert if animal found
        if animal_detected:
            alert_placeholder.markdown(
                "<h3 style='color:red;'>‚ö†Ô∏è Animal Detected Ahead! Slow Down!</h3>",
                unsafe_allow_html=True
            )
            # Play alert sound only once per detection
            if detected_name != last_alert:
                play_alert_sound()
                last_alert = detected_name

            # Add to detection log
            timestamp = time.strftime("%H:%M:%S")
            detection_log.append(f"{timestamp} - {detected_name.title()} Detected")
            st.sidebar.write(detection_log[-5:])  # show last 5 detections
        else:
            alert_placeholder.empty()
            last_alert = None  # Reset last alert when no animals

        # Show the video frame
        stframe.image(frame, channels="BGR")

        time.sleep(0.05)

    cap.release()
